{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from random import randint\n",
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AppURLopener(urllib.request.FancyURLopener):\n",
    "    version = \"Mozilla/5.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elise\\AppData\\Local\\Temp/ipykernel_24572/840657722.py:1: DeprecationWarning: AppURLopener style of invoking requests is deprecated. Use newer urlopen functions/methods\n",
      "  opener = AppURLopener()\n"
     ]
    }
   ],
   "source": [
    "opener = AppURLopener()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FormatDataOnePage():\n",
    "    # def __init__(self):\n",
    "\n",
    "    def collect_text(self, trs):\n",
    "        sequences_modern = []\n",
    "        sequences_original = []\n",
    "        for line in trs:\n",
    "            divs_original = line.find_all('div', class_='noFear__line noFear__line--original')\n",
    "            text_original = \" \".join([i.text for i in divs_original])\n",
    "\n",
    "            divs_modern = line.find_all('div', class_='noFear__line noFear__line--modern')\n",
    "            text_modern = \" \".join([i.text for i in divs_modern])\n",
    "\n",
    "            if text_original and text_modern:\n",
    "                sequences_modern.append(text_modern)\n",
    "                sequences_original.append(text_original)\n",
    "\n",
    "        return sequences_original, sequences_modern\n",
    "    \n",
    "    def make_dataframe(self, trs):\n",
    "        sequences_original, sequences_modern = self.collect_text(trs)\n",
    "        df = pd.DataFrame({'original' : sequences_original,\n",
    "                        'modern' : sequences_modern\n",
    "                        })\n",
    "        return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hamlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "acts_and_scenes = {1: range(1, 6),\n",
    "                   2: range(1, 3),\n",
    "                   3: range(1, 5),\n",
    "                   4: range(1, 8),\n",
    "                   5: range(1, 3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://www.sparknotes.com/nofear/shakespeare/hamlet/act-{}-scene-{}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatDataOnePage = FormatDataOnePage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act 1 scene 1 done, 59 lines\n",
      "act 1 scene 2 done, 73 lines\n",
      "act 1 scene 3 done, 27 lines\n",
      "act 1 scene 4 done, 30 lines\n",
      "act 1 scene 5 done, 60 lines\n",
      "act 2 scene 1 done, 37 lines\n",
      "act 2 scene 2 done, 156 lines\n",
      "act 3 scene 1 done, 48 lines\n",
      "act 3 scene 2 done, 133 lines\n",
      "act 3 scene 3 done, 12 lines\n",
      "act 3 scene 4 done, 57 lines\n",
      "act 4 scene 1 done, 11 lines\n",
      "act 4 scene 2 done, 15 lines\n",
      "act 4 scene 3 done, 26 lines\n",
      "act 4 scene 4 done, 17 lines\n",
      "act 4 scene 5 done, 63 lines\n",
      "act 4 scene 6 done, 9 lines\n",
      "act 4 scene 7 done, 41 lines\n",
      "act 5 scene 1 done, 103 lines\n",
      "act 5 scene 2 done, 140 lines\n"
     ]
    }
   ],
   "source": [
    "temp_dfs = []\n",
    "for act, scenes in acts_and_scenes.items():\n",
    "    for scene in scenes:\n",
    "        url = base_url.format(act, scene)\n",
    "        html = opener.open(url)\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        lines = soup.find_all('tr')\n",
    "        df_act = formatDataOnePage.make_dataframe(lines)\n",
    "        temp_dfs.append(df_act)\n",
    "        print(f\"act {act} scene {scene} done, {len(df_act)} lines\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hamlet = pd.concat(temp_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hamlet.index = range(len(df_hamlet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hamlet.to_csv('books\\hamlet.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Macbeth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScrapFullBook():\n",
    "    def __init__(self, title):\n",
    "        self.title = title\n",
    "    \n",
    "    def make_urls(self):\n",
    "        self.main_url = 'https://www.sparknotes.com/nofear/shakespeare/{}/'.format(self.title)\n",
    "        self.text_url = self.main_url + 'act-{}-scene-{}/'\n",
    "\n",
    "    def soup_from_url(self, url):\n",
    "        html = opener.open(url)\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        return soup\n",
    "\n",
    "    def collect_text(self, trs):\n",
    "        sequences_modern = []\n",
    "        sequences_original = []\n",
    "        for line in trs:\n",
    "            divs_original = line.find_all('div', class_='noFear__line noFear__line--original')\n",
    "            text_original = \" \".join([i.text for i in divs_original])\n",
    "\n",
    "            divs_modern = line.find_all('div', class_='noFear__line noFear__line--modern')\n",
    "            text_modern = \" \".join([i.text for i in divs_modern])\n",
    "\n",
    "            if text_original and text_modern:\n",
    "                sequences_modern.append(text_modern)\n",
    "                sequences_original.append(text_original)\n",
    "\n",
    "        return sequences_original, sequences_modern\n",
    "    \n",
    "    def make_dataframe_scene(self, trs):\n",
    "        sequences_original, sequences_modern = self.collect_text(trs)\n",
    "        df = pd.DataFrame({'original' : sequences_original,\n",
    "                        'modern' : sequences_modern\n",
    "                        })\n",
    "        return df\n",
    "    \n",
    "    def get_acts_and_scenes_number(self):\n",
    "        full_page_soup = self.soup_from_url(self.main_url)\n",
    "        acts_html = full_page_soup.find_all('div', class_='texts-landing-page__toc__section')\n",
    "\n",
    "        acts_and_scenes = {}\n",
    "        for i in range(len(acts_html)):\n",
    "            n_max_scenes = len(acts_html[i].find_all('ul', class_='texts-landing-page__toc__section__list'))\n",
    "            acts_and_scenes[i+1] = range(1, n_max_scenes + 1)\n",
    "        \n",
    "        return acts_and_scenes\n",
    "\n",
    "    def get_all_text(self):\n",
    "        self.make_urls()\n",
    "        self.acts_and_scenes = self.get_acts_and_scenes_number()\n",
    "        temp_dfs = []\n",
    "        for act, scenes in self.acts_and_scenes.items():\n",
    "            for scene in scenes:\n",
    "                url = self.text_url.format(act, scene)\n",
    "                soup_scene = self.soup_from_url(url)\n",
    "                lines = soup_scene.find_all('tr')\n",
    "                df_act = formatDataOnePage.make_dataframe(lines)\n",
    "                temp_dfs.append(df_act)\n",
    "                print(f\"act {act} scene {scene} done, {len(df_act)} lines\")\n",
    "        \n",
    "        df_full = pd.concat(temp_dfs)\n",
    "        df_full.index = range(len(df_full))\n",
    "        df_full.to_csv(f'books\\{self.title}.csv')\n",
    "        return df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrapMacbeth = ScrapFullBook('macbeth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act 1 scene 1 done, 8 lines\n",
      "act 1 scene 2 done, 18 lines\n",
      "act 1 scene 3 done, 50 lines\n",
      "act 1 scene 4 done, 12 lines\n",
      "act 1 scene 5 done, 15 lines\n",
      "act 1 scene 6 done, 7 lines\n",
      "act 1 scene 7 done, 13 lines\n",
      "act 2 scene 1 done, 17 lines\n",
      "act 2 scene 2 done, 29 lines\n",
      "act 2 scene 3 done, 60 lines\n",
      "act 2 scene 4 done, 22 lines\n",
      "act 3 scene 1 done, 34 lines\n",
      "act 3 scene 2 done, 13 lines\n",
      "act 3 scene 3 done, 20 lines\n",
      "act 3 scene 4 done, 54 lines\n",
      "act 3 scene 5 done, 5 lines\n",
      "act 3 scene 6 done, 5 lines\n",
      "act 4 scene 1 done, 55 lines\n",
      "act 4 scene 2 done, 37 lines\n",
      "act 4 scene 3 done, 65 lines\n",
      "act 5 scene 1 done, 27 lines\n",
      "act 5 scene 2 done, 10 lines\n",
      "act 5 scene 3 done, 19 lines\n",
      "act 5 scene 4 done, 10 lines\n",
      "act 5 scene 5 done, 14 lines\n",
      "act 5 scene 6 done, 3 lines\n",
      "act 5 scene 7 done, 12 lines\n",
      "act 5 scene 8 done, 21 lines\n"
     ]
    }
   ],
   "source": [
    "df_macbeth = scrapMacbeth.get_all_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act 1 scene 1 done, 45 lines\n",
      "act 1 scene 2 done, 31 lines\n",
      "act 1 scene 3 done, 89 lines\n",
      "act 2 scene 1 done, 85 lines\n",
      "act 2 scene 2 done, 1 lines\n",
      "act 2 scene 3 done, 96 lines\n",
      "act 3 scene 1 done, 23 lines\n",
      "act 3 scene 2 done, 3 lines\n",
      "act 3 scene 3 done, 164 lines\n",
      "act 3 scene 4 done, 84 lines\n",
      "act 4 scene 1 done, 136 lines\n",
      "act 4 scene 2 done, 98 lines\n",
      "act 4 scene 3 done, 37 lines\n",
      "act 5 scene 1 done, 74 lines\n",
      "act 5 scene 2 done, 164 lines\n"
     ]
    }
   ],
   "source": [
    "scrapOthello = ScrapFullBook('othello')\n",
    "df_othello = scrapOthello.get_all_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act 1 scene 1 done, 85 lines\n",
      "act 1 scene 2 done, 42 lines\n",
      "act 1 scene 3 done, 7 lines\n",
      "act 1 scene 4 done, 112 lines\n",
      "act 1 scene 5 done, 25 lines\n",
      "act 2 scene 1 done, 42 lines\n",
      "act 2 scene 2 done, 58 lines\n",
      "act 2 scene 3 done, 1 lines\n",
      "act 2 scene 4 done, 96 lines\n",
      "act 3 scene 1 done, 11 lines\n",
      "act 3 scene 2 done, 15 lines\n",
      "act 3 scene 3 done, 4 lines\n",
      "act 3 scene 4 done, 56 lines\n",
      "act 3 scene 5 done, 8 lines\n",
      "act 3 scene 6 done, 34 lines\n",
      "act 3 scene 7 done, 53 lines\n",
      "act 4 scene 1 done, 29 lines\n",
      "act 4 scene 2 done, 30 lines\n",
      "act 4 scene 3 done, 21 lines\n",
      "act 4 scene 4 done, 6 lines\n",
      "act 4 scene 5 done, 18 lines\n",
      "act 4 scene 6 done, 86 lines\n",
      "act 4 scene 7 done, 42 lines\n",
      "act 5 scene 1 done, 28 lines\n",
      "act 5 scene 2 done, 6 lines\n",
      "act 5 scene 3 done, 127 lines\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scraplear= ScrapFullBook('lear')\n",
    "df_lear = scraplear.get_all_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e8433e473730bff5a1645d48df9d361cdd2d490842c0afe14fe644c87fbaf516"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('deep')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
